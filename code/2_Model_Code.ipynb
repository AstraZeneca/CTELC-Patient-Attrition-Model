{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Trial Patient Attrition Modeling Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Authors\n",
    "Nampally, Sreenath; Zhang, Youyi; Khan A.N, Imran; Hutchison, Emmette; Khader, Shameer; Khan, Faisal.\n",
    "### Contact\n",
    "shameer.khader@astrazeneca.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Project\n",
    "This work assembled the first large-scale sponsor independent clinical trial dataset for the purpose of enabling a data-driven approach to elucidate the drivers of patient attrition in clinical trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Code\n",
    "Data is injested after spliting into Train and Test for R Superlearner code to run (Ensemble). SuperLearner is an algorithm that uses cross-validation to estimate the performance of multiple machine learning models, or the same model with different settings. It then creates an optimal weighted average of those models, aka an “ensemble”, using the test data performance. This approach has been proven to be asymptotically as accurate as the best possible prediction algorithm that is tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the relevant libraries \n",
    "library(\"SuperLearner\")\n",
    "library(\"MASS\")\n",
    "library(\"ranger\")\n",
    "library(\"ipred\")\n",
    "library(\"kernlab\")\n",
    "library(\"arm\")\n",
    "library(\"dplyr\")\n",
    "library(\"caret\")\n",
    "library(\"glmnet\")\n",
    "library(\"parallel\")\n",
    "library(\"randomForest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directories\n",
    "setwd(choose.dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the following data sets \n",
    "# Total_dataset/ds1 = Total/Full Dataset\n",
    "# Training_split/ds3 = Training Dataset\n",
    "# Testing_split/ds4 = Test Dataset\n",
    "\n",
    "load(\"Total_dataset.RData\")\n",
    "load(\"Training_split.RData\")\n",
    "load(\"Testing_split.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Character columns to numeric in the training data set ds3\n",
    "# ***remove numerics ****\n",
    "ds3$Disease_n <- as.numeric(as.factor(ds3$Disease))\n",
    "ds3$Phase_n <- as.numeric(as.factor(ds3$Phase))\n",
    "ds3$Industry_n <- as.numeric(as.factor(ds3$Industry))\n",
    "\n",
    "# Remove the character columns and other un necessary columns \n",
    "ds3 <- ds3[, !(names(ds3) %in% c(\"nct_id\",\"dwp_wo_ae\",\"dwp_sub\", \"Disease\", \"Phase\", \"Industry\") )] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Character columns to numeric in the test data set ds4\n",
    "ds4$Disease_n <- as.numeric(as.factor(ds4$Disease))\n",
    "ds4$Phase_n <- as.numeric(as.factor(ds4$Phase))\n",
    "ds4$Industry_n <- as.numeric(as.factor(ds4$Industry))\n",
    "\n",
    "# Remove the character columns and other target columns \n",
    "ds4 <- ds4[, !(names(ds4) %in% c(\"nct_id\",\"dwp_wo_ae\",\"dwp_sub\", \"dwp_all_res\", \"dwp_all_pred\", \"Disease\", \"Phase\", \"Industry\") )] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test and training data set from ds3 and ds4\n",
    "superlearner_train <- ds3\n",
    "superlearner_test <- ds4\n",
    "\n",
    "# Separate the predictors in to its own data frame for training data set\n",
    "x.train <- subset(superlearner_train, select = -dwp_all)\n",
    "y.train <- superlearner_train$dwp_all\n",
    "\n",
    "\n",
    "# Separate the predictors in to its own data frame for test data set\n",
    "x.test <- subset(superlearner_test, select = -dwp_all)\n",
    "y.test <- superlearner_test$dwp_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the most important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"party\")\n",
    "library(party)\n",
    "cf1 <- cforest(y.train ~ . , data= x.train, control=cforest_unbiased(mtry=2,ntree=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp(cf1) # get variable importance, based on mean decrease in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Wrapper algorithms available in SuperLearner\n",
    "listWrappers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new function that changes just the ntree argument for RandomForest\n",
    "# \"...\" means \"all other arguments that were sent to the function\"\n",
    "\n",
    "SL.rf.better <- function(...){\n",
    "      SL.randomForest(..., num.trees=5000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the CV.SuperLearner with the tuned randomforest along with others.  \n",
    "\n",
    "system.time({\n",
    "# Set the seed\n",
    "set.seed(150)\n",
    "    \n",
    "# Create a library of algorithms\n",
    "SL.library <- c(\"SL.ranger\", \"SL.rf.better\", \"SL.randomForest\", \"SL.ksvm\", \"SL.ipredbagg\", \"SL.bayesglm\", \"SL.glm\", \"SL.lm\", \"SL.glmnet\", \"SL.ridge\", \"SL.mean\")\n",
    "\n",
    "\n",
    "# Tune the model\n",
    "# The outercross-validation is the sample spliting for evaluating the SuperLearner.\n",
    "# The inner cross-validation are the valuesnpassed to each of the V SuperLearner calls.\n",
    "# V is the number of folds for CV.SuperLearner\n",
    "cv.model.tune <- CV.SuperLearner(Y = y.train, X = x.train, family=gaussian(), SL.library = SL.library, \n",
    "                            verbose = TRUE, method = \"method.NNLS\", cvControl = list(V = 10, shuffle = FALSE),\n",
    "                           innerCvControl = list(list(V = 5)))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "summary(cv.model.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- summary(cv.model.tune)\n",
    "newdf <- df$Table\n",
    "mse <- newdf[,1:2]\n",
    "mse$rmse ='^'(mse$Ave,1/2) # square root of mse to calculate rmse\n",
    "finaltable <- mse[c(1,2,5,6,7,8,9,10),c(1,3)] # subset only few algorithms\n",
    "standardnames <- c('Super Learner', 'Discrete Super Learner', 'Random Forest', 'Support Vector Machines', 'Bagging Classification', 'Bayesian Generalized Linear Models\n",
    "', 'Generalized Linear Models', 'Ordinary least squares' ) # standardize the names\n",
    "final_stats_with_rmse <- data.frame(\"Algorithms\" = standardnames, \"RMSE\" = finaltable[,2]) # subset the data\n",
    "final_stats_with_rmse %>% mutate_at(vars(RMSE), funs(round(., 2))) # round columns values to two decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting top 8 features based on variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.train_selected_vars <- x.train %>% dplyr::select(Duration.Trial, Duration.Treatment, Disease_n, AE_total_serious, N_total, GDP_weighted, AA_fraction, Age_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the CV.SuperLearner with the tuned randomforest along with lm on final selected variables  \n",
    "\n",
    "system.time({\n",
    "# Set the seed\n",
    "set.seed(250)\n",
    "    \n",
    "# Create a library of algorithms\n",
    "SL.library <- c(\"SL.randomForest\", \"SL.lm\")\n",
    "\n",
    "\n",
    "# Tune parameters for SL : stratifyCV, shuffle and validRows\n",
    "# The outercross-validation is the sample spliting for evaluating the SuperLearner.\n",
    "# The inner cross-validation are the valuesnpassed to each of the V SuperLearner calls.\n",
    "# V is the number of folds for CV.SuperLearner\n",
    "# A list of parameters to control the outer cross-validation process. cvControl set to 3\n",
    "cv.model.tune.8predictors <- CV.SuperLearner(Y = y.train, X = x.train_selected_vars, family=gaussian(), SL.library = SL.library, \n",
    "                            verbose = TRUE, method = \"method.NNLS\", cvControl = list(V = 3, shuffle = FALSE),\n",
    "                           innerCvControl = list(list(V = 5)))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics\n",
    "summary(cv.model.tune.8predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- summary(cv.model.tune.8predictors)\n",
    "newdf <- df$Table\n",
    "mse <- newdf[,1:2]\n",
    "mse$rmse ='^'(mse$Ave,1/2) # square root of mse to calculate rmse\n",
    "finaltable <- mse[c(3,4),c(1,3)] # subset only few algorithms\n",
    "standardnames <- c('Random Forest','Ordinary least squares' ) # standardize the names\n",
    "final_stats_with_rmse <- data.frame(\"Algorithms\" = standardnames, \"RMSE\" = finaltable[,2]) # subset the data\n",
    "final_stats_with_rmse %>% mutate_at(vars(RMSE), funs(round(., 2))) # round columns values to two decimal places"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
